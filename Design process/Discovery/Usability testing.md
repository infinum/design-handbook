Usability is the ability to use a product with ease. When we talk about usability, we make sure that products are easy to use for everyone in whatever context of usage. It should be evident to people where they are, what they are supposed to do next and to be able to complete the necessary task. From the design perspective, we want our users to have a product that is easy to use without much thought and any frustrations.


# How to conduct usability testing

Usability testing is a direct way of seeing how users interact with our product.

In a usability testing, we show the product to one user at a time (whether it‚Äôs a mobile application or prototype of a mobile app) and we ask them to:

a. figure out what it is <br>
b. try to use the prototype to do a typical task.

Usability Testing is crucial because it can help us to learn about whether we designed our application based on our user's behaviours and expectations, and we can get many ideas for improving the design. We usually perform ‚Äútask testing‚Äù ‚Äî we ask the user to do complete a task, and then we observe how well they do.

If it‚Äôs the first time you‚Äôre running a usability testing, don‚Äôt hesitate to ask a more experienced colleague for advice, help or quick walkthrough.

For each usability testing, we need at least two persons to set everything up:

a. facilitator, <br>
b. observer.

Preferably two designers, but you can take someone from the project team (i.e. QA). If you are the lead designer on the project, don‚Äôt take the user feedback personally and try to avoid bias towards users‚Äô opinions.

**The facilitator** is one of the most critical roles in usability testing. It needs to be someone who tends to be patient, calm, empathetic; and a good listener.

**The observer** is someone who tracks the testing in-person, via Lookback or video call, takes notes and cares about the tech setup (phones, batteries)


We can divide usability testing into 3 phases:  

1. Setting up ‚Äî planning and preparing everything we need for testing
2. Conducting usability testing ‚Äî live or remote sessions with the users
3. Aftermath ‚Äî analysing the results and delivering a report

The following paragraphs will guide you through each of these phases.




## 1. Setting up

Organization of a usability testing depends on many factors (the number of participants, hosting location, etc.). Usually, there are two options: 

1. **Infinum** will find users and host the testing
2. **The client** will find users and host the testing

In case Infinum needs to find users, please consult with a colleague who has already done this before.

However, the most common use case is ‚Äî the client will find users and host the testing. Here is the breakdown of the necessary steps:


1. Send üóù [**Statement of Consent and Confidentiality statement**](https://drive.google.com/open?id=1OzQrCEtUuzfynynlDKRyg5b5PMbdBDkv) documents to your project‚Äôs PM and the client to make sure if everything is okay from a legal standpoint.
2. Make sure to tell the client early on who is recruiting participants and where the testing will take place. In this case, the client will take care of both.
3. Go over the üóù [**document with requirements**](https://drive.google.com/open?id=1Y_MU8k9fB28ZmW251tuiz1whPV7NIVb2) with the client in person or on a call. Don‚Äôt forget to send the document in the followup mail. 

Here‚Äôs an example of a mail we send alongside the requirements doc:

> Hi everyone,<br>
> I am sending the Usability testing requirements document with information about the criteria for setting the remote usability testing:<br>
> <br>
> Participants requirements:<br>
> - from Ghana<br>
> - fluent in English<br>
> - have at least 1-year experience using the mobile applications<br>
> - be between the ages of 25-45<br>
> <br>
> Mobile set-up:<br>
> - Mobile phone for testing purposes Sony Xperia XZ (with Android 8.0 installed) or similar device (not older devices)<br>
> - installed InVision application on the mobile device for testing<br>
> - installed Participate application on the mobile device for testing<br>
> - High-speed Internet connection<br>
> <br>
> Methodology:<br>
> - Thinking aloud protocol will be used<br>
> - Users will be given 5-6 tasks<br>
> - Users will read each task aloud<br>
> - Users will complete a short questionnaire between each task<br>
> - Testing schedule: each session (per user) is scheduled for 40 minutes with 20 minutes between each session<br>
><br>
> Training online session for a facilitator in Ghana:<br>
> - Call meeting during which our design team will explain how to conduct usability testing<br>
> - One (maybe two) internal usability testing conducted in real conditions for training purposes<br>
> If you have any questions let me know.<br>
> <br>
> Regards,<br>
> Your name


4. Send the [**testing schedule table**](https://docs.google.com/spreadsheets/d/1Qe3JTMC-OTln9CbZJO5DycNsektAJVaoOzdG0r0jyRA/edit?usp=sharing) to the client. Keep in mind that each session takes about 60 min per person (40 min of interacting with the participant, 20 min for reviewing and preparing for the next participant). Keep a maximum of 5 participants per day. In case the testing is conducted remotely, or in a different country, keep time zones in mind when planning and scheduling. 


    
5. Prepare an üóù [**agenda**](https://drive.google.com/open?id=1rvcT8KHnBXLNHH8sgFlDrmshlCybZL20) for all testing sessions based on participant availability.


    Here is an example agenda for one day:

```
09:00 AM - 10:00 AM ‚Äì 1st user
10:00 AM - 11:00 AM ‚Äì 2nd user
11:00 AM - 12:00 AM ‚Äì 3rd user

12:00 AM - 01:00 PM ‚Äì Lunch & prep. for the next user*

02:00 - 03:00 PM ‚Äì 4th user
03:00 - 04:00 PM ‚Äì 5th user
04:00 - 05:00 PM - conclusions and preparation for the next day
```


6. **Define your goals** ‚Äî Before preparing specific tasks for our users, we need to define what we want to achieve. We‚Äôre looking for answers to crucial questions about usability, findability, discoverability, or general pain points. Then we use this info during the next design phase or iteration. We should ask ourself questions like:
    - Are the users aware of the main app functionalities?
    - How can we make sure they understand the content correctly?
    - Can users use the main functionalities effortlessly?
    - What dilemmas did we run into while designing? How can we be sure users won‚Äôt run into the same issues?
    These goals will help you focus while preparing the tasks.
    
7. **Prepare tasks** ‚Äî After the client approved the agenda and after the responsibilities are assigned, the facilitator starts to prepare tasks and prototype(s). You should print tasks on individual cards. Participants should be given one task at a time and they should read the text out loud before performing the task. If the participant can't solve the task after a couple of minutes, suggest that they read the text out loud again. Be wary of the wording you're using on tasks; you don't want to give away the answer by mentioning the exact copy that is visible on the screen. 
    The observer should have a list of all tasks with additional notes. These notes should specifically instruct them on what to look for while the user is completing a task. For a more in-depth study of this process, take a look at [**NNG‚Äôs guide**](https://www.nngroup.com/articles/task-scenarios-usability-testing/).
7. Prepare [**task rating tables**](https://drive.google.com/drive/folders/1vCQEJyaTYtFupEq3pHisLsXrkUzHGqbq?usp=sharing). Task rating tables are used for measuring success on each task and to have an objective overview of pain points and room for improvement.
8. Print out these documents:<br> 
<br> - Statement of Consent (equal to the number of participants),
<br> - Confidentiality statement (NDA) (equal to the number of participants),
<br> - Interviewer guides (1 copy),
<br> - Tasks for participants (1 copy of each task),
<br> - Tasks with additional notes for the observer (1 copy of each task),
<br> - Task rating tables (equals the number of participants √ó number of tasks).
9. Define mobile devices which you will user in the testing sessions. You can use new phones, but always check if Participate (from Lookback) and InVision support that specific phone and operating system. To be sure, don‚Äôt use the latest devices, because they maybe didn‚Äôt get to fix all bugs. Here‚Äôs a list of [compatible Android devices](https://help.lookback.io/troubleshooting/android-device-compatibility) for Lookback. Prepare 2 devices for each platform because the battery drains fast when you‚Äôre doing testings in a row. Assign who is responsible for charging the batteries before the sessions (usually the observer).
10. Install [**Participate**](https://lookback.io/features/participate/) on the mobile phones.
11. As a thank you for participants, we usually give out rewards (vouchers or cash). Make sure to check with the client who‚Äôs responsible for preparing these rewards.

**Preparing the project on Lookback and testing device**

1. Login to [**Lookback**](http://lookback.io) and go to *Dashboard* ‚Üí *New project*
2. Choose the device type
3. Name the project and skip the rest
4. Open the link for the InVision prototype on the testing device (in the native browser)
5. On iOS - click share and ‚Äú*Add to home screen*‚Äù (Safari)
    On Android - click more and ‚Äú*Add to home screen*‚Äù
6. The link should now be on the home screen and look like an app icon with InVision‚Äôs logo



## 2. Conducting usability testing

### Do a test run
Before the official user sessions, make sure you do a test run. Simulate a testing in Infinum‚Äôs offices and choose a colleague most similar to the target audience. Participants include: 

- the user, 
- facilitator, 
- and observer. 

We do test runs to notice smaller issues and any improvements we can make before conducting the actual testing.

### Preparing the session
Before the user enters the room, we have to set everything up:

1. Open [**Lookback**](http://lookback.io) on desktop (in Chrome) and go to your project.
2. Click on the *Live button* and copy the link.
3. Paste the link in a web browser on the testing device.
4. Choose ‚Äú*I already have Participate**‚Äù*
5. For the name write - *User 1,* *User 2, ‚Ä¶* (the email can be your email or something random)
6. Turn on the audio and camera
7. *‚ÄúStart broadcast‚Äù*
8. Go to the Lookback on desktop and open the green live session
9. ‚Äú*Start session*‚Äù and *‚ÄúCall participant‚Äù*
10. Answer the call on the test device 
11. On Android - click *‚ÄúShow my screen‚Äù*
12. Leave the Participate app open in the background and open the InVision link added to home screen


### The session

1. At the beginninng, make sure the user feels comfortable and calm. Be friendly, so the user feels relaxed, but not too friendly because we need to get objective answers and opinions from them. In true Balkan manner, offer them some juice and snacks.
2. Next, we use a script with [**Interview guides**](https://drive.google.com/drive/folders/1HZk2ez9spfpvNBYwz68wOcP9kX06-4EW?usp=sharing) to conduct usability testing, and always keep the text in front of you. Don‚Äôt hesitate to read from it but I find it‚Äôs ok to ad-lib a little, even if it means making mistakes. When the users see that you are comfortable with making mistakes, it helps take the pressure off them.
3. You have to make it clear before you start that nothing we do or say is personal and they can always ask questions. You need to tell them that sometimes giving the answers too soon will affect the testing and you will wait until the end of the session to answer their questions. It‚Äôs important to mention this because it will seem rude not to answer their questions as you go along. If you want honest answers, it can be useful to point out you did not work on this project (whether that‚Äôs true or not) and that you are just overseeing the testing.
4. Give the üóù [**Statement of Consent and Confidentiality statement**](https://drive.google.com/open?id=1OzQrCEtUuzfynynlDKRyg5b5PMbdBDkv) (when mentioned in the Interviewer guides). 
    **Statement of** **Consent** ‚Äî explain that we will record the screen and the user's face and use it only for purpose of this research. 
    **Confidentiality statement** ‚Äî point out that all the information regarding the app and this testing is confidential. Your role here is not to come across as an expert but as a good listener, so don‚Äôt hesitate to admit your ignorance about anything.
5. After reading [**Interview guides**](https://drive.google.com/drive/folders/1HZk2ez9spfpvNBYwz68wOcP9kX06-4EW?usp=sharing), give the user the üóù [**Out loud instruction**](https://drive.google.com/open?id=14SzICkNuCsTBJKXacZafm-YL4QD_VTZc) document. This activity helps the user to be comfortable with talking out loud. Give the first **task**. It is crucial to give only one task at the time so the user can focus. The user will do an excellent job by thinking out loud on their own. If they don‚Äôt, encourage them to do so. It's ok to ask questions like ‚ÄúWhat are you thinking?‚Äù or ‚ÄúWhat do you think‚Ä¶‚Äù to get them to start talking about their experience but try not to evoke a conversation. Talking too much at inappropriate times, or leading the user can affect what they do and say, which can ruin in part or all of the research findings. From here on, observe while the participants try to complete the given task, letting them continue until either:
<br> - they finished the task,
<br> - they get frustrated,
<br> - we‚Äôre not learning anything new by watching them try to muddle through.
<br>If the participant can't solve the task after a couple of minutes, suggest that they read it out loud again. Remind the user during the task to tell you when they think they are done.
7. After the task - give a [**task rating table**](https://drive.google.com/drive/folders/1vCQEJyaTYtFupEq3pHisLsXrkUzHGqbq?usp=sharing) for that specific task.
8. After each task, while the user is filling out the task rating table, the facilitator prepares the prototype for the next task. Set up the prototype on the screen where the next task begins and make sure everything is working.
9. If you're don earlier than you've planned, ask the user some questions regarding general impressions or specific features (interview-style).
9. When you are done with the session, don't forget to give the user their reward for participating.
10. Make sure that you have 10-15 minutes before the next session, so that you can prepare everything again.


## 3. Aftermath

After the session, or after all sessions, enter data collected from the task rating tables into the üóù [**Task rating spreadsheet**](https://drive.google.com/open?id=1yM2OfOHQ_AFMomjRM2qYgOk0KNkPZatP4Xn3vOgVUEo). 

Go through the observer's notes and video recordings of the users and see what were the pain points in each task and what can we do to improve them. 

Write a üóù [**Usability testing report**](https://drive.google.com/open?id=1fXj4RKvXOW3iMmq16TImNRqvucTmIHSx) ‚Äî a document with general findings from the usability testing (we need to send this to the clients). Based on that document, create a keynote presentation to go over the results with clients.


## Resources

- Google Drive: [Usability testing kit](https://drive.google.com/open?id=1M9cFJ3-8UsrbWD7ffMdWbJDLIiDGxI2k)
- [Maze's Guide to Usability Testing](https://maze.design/guides/usability-testing)
